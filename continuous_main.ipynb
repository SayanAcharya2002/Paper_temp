{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random,os,time\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import itertools as it\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abalone.csv',\n",
       " 'abalone19.csv',\n",
       " 'abalone9-18.csv',\n",
       " 'bupa.csv',\n",
       " 'cancer_classification.csv',\n",
       " 'continuous_main.ipynb',\n",
       " 'contin_main_all_together.ipynb',\n",
       " 'hayes-roth.csv',\n",
       " 'kddcup-guess_passwd_vs_satan.csv',\n",
       " 'led7digit-0-2-4-5-6-7-8-9_vs_1.csv',\n",
       " 'main.ipynb',\n",
       " 'new-thyroid.csv',\n",
       " 'page-blocks_csv.csv',\n",
       " 'poker-9_vs_7.csv',\n",
       " 'results',\n",
       " 'segment0.csv',\n",
       " 'SPECTF.csv',\n",
       " 'yeast5.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files=os.listdir()\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FILE DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlpath='https://raw.githubusercontent.com/ahmed-shameem/Class_imbalance/master/CI_Datasets/bupa.data'\n",
    "file_name=urlpath.split('/')[-1]\n",
    "if not os.path.exists('file_name'):\n",
    "  os.system(f\"curl --url {urlpath} -o {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abalone.csv',\n",
       " 'abalone19.csv',\n",
       " 'abalone9-18.csv',\n",
       " 'bupa.csv',\n",
       " 'bupa.data',\n",
       " 'cancer_classification.csv',\n",
       " 'continuous_main.ipynb',\n",
       " 'contin_main_all_together.ipynb',\n",
       " 'hayes-roth.csv',\n",
       " 'kddcup-guess_passwd_vs_satan.csv',\n",
       " 'led7digit-0-2-4-5-6-7-8-9_vs_1.csv',\n",
       " 'main.ipynb',\n",
       " 'new-thyroid.csv',\n",
       " 'page-blocks_csv.csv',\n",
       " 'poker-9_vs_7.csv',\n",
       " 'results',\n",
       " 'segment0.csv',\n",
       " 'SPECTF.csv',\n",
       " 'yeast5.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='page-blocks_csv.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>lenght</th>\n",
       "      <th>area</th>\n",
       "      <th>eccen</th>\n",
       "      <th>p_black</th>\n",
       "      <th>p_and</th>\n",
       "      <th>mean_tr</th>\n",
       "      <th>blackpix</th>\n",
       "      <th>blackand</th>\n",
       "      <th>wb_trans</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.657</td>\n",
       "      <td>2.33</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.741</td>\n",
       "      <td>4.43</td>\n",
       "      <td>31</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.743</td>\n",
       "      <td>4.33</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>4</td>\n",
       "      <td>524</td>\n",
       "      <td>2096</td>\n",
       "      <td>131.000</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.603</td>\n",
       "      <td>40.57</td>\n",
       "      <td>1136</td>\n",
       "      <td>1264</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.929</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>570</td>\n",
       "      <td>15.833</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.911</td>\n",
       "      <td>1.64</td>\n",
       "      <td>171</td>\n",
       "      <td>519</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>287</td>\n",
       "      <td>5.857</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.801</td>\n",
       "      <td>1.36</td>\n",
       "      <td>61</td>\n",
       "      <td>230</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5473 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height  lenght  area    eccen  p_black  p_and  mean_tr  blackpix  \\\n",
       "0          5       7    35    1.400    0.400  0.657     2.33        14   \n",
       "1          6       7    42    1.167    0.429  0.881     3.60        18   \n",
       "2          6      18   108    3.000    0.287  0.741     4.43        31   \n",
       "3          5       7    35    1.400    0.371  0.743     4.33        13   \n",
       "4          6       3    18    0.500    0.500  0.944     2.25         9   \n",
       "...      ...     ...   ...      ...      ...    ...      ...       ...   \n",
       "5468       4     524  2096  131.000    0.542  0.603    40.57      1136   \n",
       "5469       7       4    28    0.571    0.714  0.929    10.00        20   \n",
       "5470       6      95   570   15.833    0.300  0.911     1.64       171   \n",
       "5471       7      41   287    5.857    0.213  0.801     1.36        61   \n",
       "5472       8       1     8    0.125    1.000  1.000     8.00         8   \n",
       "\n",
       "      blackand  wb_trans  class  \n",
       "0           23         6      1  \n",
       "1           37         5      1  \n",
       "2           80         7      1  \n",
       "3           26         3      1  \n",
       "4           17         4      1  \n",
       "...        ...       ...    ...  \n",
       "5468      1264        28      2  \n",
       "5469        26         2      1  \n",
       "5470       519       104      1  \n",
       "5471       230        45      1  \n",
       "5472         8         1      4  \n",
       "\n",
       "[5473 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4913\n",
       "2     329\n",
       "5     115\n",
       "4      88\n",
       "3      28\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=map(lambda x:x.strip(),df.columns)\n",
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_name==\"hayes-roth.csv\":\n",
    "  df[df.iloc[:,-1]==1]=0\n",
    "  df[df.iloc[:,-1]==2]=0\n",
    "  df[df.iloc[:,-1]==3]=1\n",
    "elif file_name=='page-blocks_csv.csv':\n",
    "  maj_index=[1,2,3,4]\n",
    "  min_index=[5]\n",
    "  for j in maj_index:\n",
    "    df[df.iloc[:,-1]==j]=1\n",
    "  for j in min_index:\n",
    "    df[df.iloc[:,-1]==j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5358\n",
       "0     115\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_train_x,final_test_x,first_train_y,final_test_y=train_test_split(X,y,test_size=0.2,random_state=int(time.time()))\n",
    "\n",
    "first_train_x_array=np.array(first_train_x)\n",
    "first_train_y_array=np.array(first_train_y)\n",
    "\n",
    "# first_train_y_array=np.reshape(first_train_y_array,newshape=(len(first_train_y_array),1))\n",
    "\n",
    "# first_=np.concatenate((first_train_x_array,first_train_y_array),axis=1)\n",
    "#final tests will be used for testing the outcome at the very end\n",
    "#for all other testing and training during pso, the first_train will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(population:np.array,model=AdaBoostClassifier(n_estimators=50,learning_rate=1)):\n",
    "  indices=[]\n",
    "  for i in range(population):\n",
    "    if population[i]==1:\n",
    "      indices.append(i)\n",
    "  total_data=df.iloc[indices,:]\n",
    "  train_x,test_x,train_y,test_y=train_test_split(total_data.iloc[:,:-1],total_data.iloc[:,-1],test_size=0.2,random_state=int(time.time()))\n",
    "  model.fit(train_x,train_y)\n",
    "  return model.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO:\n",
    "  def __init__(self,agent_num,max_iter,obj_func,train_x,test_x,train_y,test_y):\n",
    "    self.agent_num=agent_num\n",
    "    self.max_iter=max_iter\n",
    "    \n",
    "    # self.obj_func=obj_func\n",
    "    self.obj_func=self.fitness\n",
    "\n",
    "    self.train_x=train_x.copy()\n",
    "    self.test_x=test_x.copy()\n",
    "    self.train_y=train_y.copy()\n",
    "    self.test_y=test_y.copy()\n",
    "\n",
    "    self.majority_index=None\n",
    "    self.minority_index=None\n",
    "\n",
    "    self.worst_cases=None\n",
    "\n",
    "    self.p_inc=1\n",
    "\n",
    "    \n",
    "\n",
    "  def fitness(self,agent,thresold=0.5):\n",
    "    # clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    rows1 = []\n",
    "    for i in range(len(agent)):\n",
    "      if(agent[i]>thresold):\n",
    "        rows1.append(self.majority_index[i])\n",
    "\n",
    "    rows2 = self.minority_index.copy()\n",
    "\n",
    "    rows = rows1+rows2\n",
    "\n",
    "    train_data=[self.train_x[i,:] for i in rows]\n",
    "    test_data=self.test_x.copy()\n",
    "\n",
    "    # model=clf.fit(train_data,trainy[rows])\n",
    "    abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "    model=abc.fit(train_data,self.train_y[rows])\n",
    "\n",
    "    #check here possible error from here\n",
    "    #changed 1 to -1\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(self.test_y,model.predict_proba(test_data)[:,-1])\n",
    "    # false_positive_rate,true_positive_rate,thresholds=roc_curve(testy,model.predict_proba(test_data)[:,1])\n",
    "    return auc(false_positive_rate, true_positive_rate)\n",
    "  \n",
    "  def initialize(self,n,select_percent:float):\n",
    "    select_n=round(n*select_percent)\n",
    "    ans=np.zeros(shape=(self.agent_num,n))\n",
    "    for i in range(self.agent_num):\n",
    "      ans[i,random.sample(range(n),k=select_n)]=1\n",
    "    return ans\n",
    "\n",
    "  def get_all_fitness(self,population):\n",
    "    ans=[]\n",
    "    for vec in population:\n",
    "      ans.append(self.obj_func(vec))\n",
    "    ans=np.array(ans)\n",
    "    return ans\n",
    "  \n",
    "  #probably make it a class method but mehh\n",
    "  def sigmoid(self,x:float)->int:\n",
    "    threshold=0.5\n",
    "    if 1/(1+np.e**(-x))>threshold:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "  def sigmoid_transform(self,population):\n",
    "    new_population=np.zeros_like(population)\n",
    "    for i in range(len(new_population)):\n",
    "      new_population[i]=self.sigmoid(population[i])\n",
    "    return new_population\n",
    "\n",
    "  def thresolding_transform(self,agent,thresold=0.5):\n",
    "    new_agent=[0]*len(agent)\n",
    "    for i in range(len(agent)):\n",
    "      new_agent[i]=int((agent[i]>thresold))\n",
    "    return new_agent\n",
    "\n",
    "  def penalize(self,population,best_fitness_all,penalty,iter_no):\n",
    "    arg_sorted=np.argsort(best_fitness_all)\n",
    "    #keep a 2d array like (iteration_no,one_or_zero_in_worst_solution)\n",
    "    #if you see, some instance present in last 5 iterations, then penalize it.\n",
    "    #continue like this\n",
    "    \n",
    "    consider_no=5\n",
    "    self.worst_cases[iter_no]=population[np.argmin(best_fitness_all)].copy()\n",
    "\n",
    "    # 100\n",
    "    # agent0=>0 1 2 3 4.. 100\n",
    "    #         1 0 1 1 \n",
    "\n",
    "    if iter_no<consider_no:\n",
    "      return\n",
    "    to_penalize=[]\n",
    "    for i in range(np.shape(population)[1]):\n",
    "      for j in range(iter_no-consider_no+1,iter_no+1):\n",
    "        if self.worst_cases[j][i]<=0.5:\n",
    "          break\n",
    "      if j==iter_no:\n",
    "        to_penalize.append(i)\n",
    "    \n",
    "    for i in to_penalize:\n",
    "      # penalty[i]+=1\n",
    "      penalty[i]+=self.p_inc\n",
    "      # print(f\"penalized {i}, cur_penalty:{penalty[i]}\")\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "  def get_majority_minority_indices(self):\n",
    "    #work with train_data here\n",
    "    type_0=[]\n",
    "    type_1=[]\n",
    "    for i in range(len(self.train_y)):\n",
    "      if self.train_y[i]==0:\n",
    "        type_0.append(i)\n",
    "      else:\n",
    "        type_1.append(i)\n",
    "    if len(type_1)>len(type_0):\n",
    "      self.majority_index,self.minority_index=type_1,type_0\n",
    "    else:\n",
    "      self.majority_index,self.minority_index=type_0,type_1\n",
    "\n",
    "\n",
    "\n",
    "  def optimize(self,select_percent:float=0.5,p_inc:float=1,bounds=None):\n",
    "    #initializing\n",
    "    # n=np.shape(data)[0]\n",
    "    self.p_inc=p_inc\n",
    "\n",
    "    self.get_majority_minority_indices()\n",
    "\n",
    "    n=len(self.majority_index)\n",
    "    if bounds==None:\n",
    "      bounds=[0]*n\n",
    "      for i in range(len(bounds)):\n",
    "        bounds[i]=[0,1]\n",
    "    bounds=np.array(bounds)\n",
    "\n",
    "    population=self.initialize(n,select_percent)\n",
    "    penalty=np.zeros(n)\n",
    "    \n",
    "    best_fitness_all=self.get_all_fitness(population)\n",
    "    best_fitness_all_position=population.copy()\n",
    "    best_fitness_global=np.max(best_fitness_all)\n",
    "    best_fitness_global_position=population[np.argmax(best_fitness_all)].copy()\n",
    "\n",
    "    velocity=np.zeros_like(population)\n",
    "    \n",
    "    penalty_constant=1\n",
    "    # [0,2,0]*[1,1,1]=[0,2,0]=>2\n",
    "    # x=>agent\n",
    "    compound_obj_func=lambda x:self.obj_func(x)-penalty_constant*np.sum(penalty*self.thresolding_transform(x))\n",
    "\n",
    "    # TODO\n",
    "    #apply sigmoid on penalty part of the compound function to reduce dominance of the penalty\n",
    "\n",
    "\n",
    "    #just an initialization\n",
    "    self.worst_cases=[0]*self.max_iter\n",
    "\n",
    "    for iter in range(self.max_iter):\n",
    "      w=0.9-(iter/self.max_iter)*(0.9-0.4)\n",
    "      c1=1.5+np.random.random()*(2-1.5)\n",
    "      c2=2+np.random.random()*(2.5-2)\n",
    "\n",
    "      for i in range(self.agent_num):\n",
    "        temp_velo_term1=w*velocity[i]\n",
    "        # temp_velo_term2=np.multiply(np.random.random_integers(0,1,n),(best_fitness_all_position[i]-population[i]))*c1\n",
    "        temp_velo_term2=np.multiply(self.thresolding_transform(np.random.rand(n)),(best_fitness_all_position[i]-population[i]))*c1\n",
    "        # temp_velo_term3=np.multiply(np.random.random_integers(0,1,n),(best_fitness_global_position-population[i]))*c2\n",
    "        temp_velo_term3=np.multiply(self.thresolding_transform(np.random.rand(n)),(best_fitness_global_position-population[i]))*c2\n",
    "        \n",
    "        temp_velocity=temp_velo_term1+temp_velo_term2+temp_velo_term3\n",
    "        \n",
    "        #updation of velocity that i forgot\n",
    "        velocity[i]=temp_velocity\n",
    "\n",
    "        temp_population=population[i]+temp_velocity\n",
    "\n",
    "        #bringing back into bound\n",
    "        temp_population=np.clip(temp_population,0,1)\n",
    "\n",
    "        #temp_population=self.sigmoid_transform(temp_population)#making the floats 0/1\n",
    "        temp_fitness=compound_obj_func(temp_population)# calling the compound function\n",
    "        if(temp_fitness>best_fitness_all[i]):\n",
    "          population[i]=temp_population.copy()\n",
    "          best_fitness_all[i]=temp_fitness\n",
    "          best_fitness_all_position[i]=temp_population.copy()\n",
    "          if temp_fitness>best_fitness_global:\n",
    "            best_fitness_global=temp_fitness\n",
    "            best_fitness_global_position=temp_population.copy()\n",
    "        \n",
    "      self.penalize(population,best_fitness_all,penalty,iter)\n",
    "\n",
    "    ans_to_return=self.dataset_indices(best_fitness_global_position)\n",
    "    return ans_to_return\n",
    "\n",
    "\n",
    "  def dataset_indices(self,agent):\n",
    "    rows=[]\n",
    "    for i in range(len(agent)):\n",
    "      if agent[i]==1:\n",
    "        rows.append(self.majority_index[i])\n",
    "    rows+=self.minority_index\n",
    "    return rows\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def calc_fitness(train_x,final_test_x,train_y,final_test_y):\n",
    "\n",
    "    abc = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "    model=abc.fit(train_x,train_y)\n",
    "\n",
    "    #check here possible error from here\n",
    "    #changed 1 to -1\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(final_test_y,model.predict_proba(final_test_x)[:,-1])\n",
    "    # false_positive_rate,true_positive_rate,thresholds=roc_curve(testy,model.predict_proba(test_data)[:,1])\n",
    "    return auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameter_list=[\n",
    "  (0.3,0.01),\n",
    "  (0.4,0.01),\n",
    "  (0.4,0.5),\n",
    "  (0.5,1),\n",
    "  (0.5,0.01),\n",
    "  (0.5,0.05),\n",
    "  (0.5,3),\n",
    "  (0.7,1),\n",
    "  (0.7,3),\n",
    "  (0.7,0.01),\n",
    "  (0.7,0.1),\n",
    "  (0.3,1),\n",
    "  (0.5,2),\n",
    "  (0.5,0.5),\n",
    "  (0.7,1),\n",
    "  (0.7,0.05),\n",
    "  (0.4,0.1),\n",
    "  (0.4,1),\n",
    "  (0.5,3),\n",
    "  (0.5,0.001),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper_parameter_list=[\n",
    "#   (0.3,1),\n",
    "#   (0.5,2),\n",
    "#   (0.5,0.5),\n",
    "#   (0.7,1),\n",
    "#   (0.7,0.05),\n",
    "#   (0.4,0.1),\n",
    "#   (0.4,1),\n",
    "#   (0.5,3),\n",
    "#   (0.5,0.001),\n",
    "# ]\n",
    "hyper_parameter_list=set(hyper_parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_agent,max_iter,select_percent,p_inc\n",
    "all_agent_nums=range(10,40,10)\n",
    "all_max_iternums=range(10,30,5)\n",
    "# all_select_percent_s=[0.3,0.5,0.7]\n",
    "all_select_percent_s=[0.5,0.7]\n",
    "# all_p_incs=[0.01,0.05,0.1,3]\n",
    "all_p_incs=[0.01,0.1,0.5]\n",
    "new_hyperparameter_list=list(it.product(all_agent_nums,all_max_iternums,all_select_percent_s,all_p_incs))\n",
    "len(new_hyperparameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hyperparameter_list=list(it.product([10,20,30,40,50],[50],[0.5],[0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sayan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sayan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sayan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\sayan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but AdaBoostClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "for agent_num,max_iter,select_percent,p_inc in new_hyperparameter_list :\n",
    "  train_x,test_x,train_y,test_y=train_test_split(first_train_x_array,first_train_y_array,test_size=0.2,random_state=round(time.time()))\n",
    "  model=PSO(agent_num,max_iter,None,train_x,test_x,train_y,test_y)\n",
    "  rows=model.optimize(select_percent,p_inc)\n",
    "  \n",
    "  # result_entry=[file_name,len(df[df.iloc[:,-1]==1]),np.count_nonzero(train_y[rows]),np.count_nonzero(final_test_y),len(train_x),len(rows),select_percent,p_inc,calc_fitness(train_x[rows],final_test_x,train_y[rows],final_test_y)]\n",
    "  # all_results.append(result_entry)\n",
    "  \n",
    "  new_result=f\"{file_name},{agent_num},{max_iter},{select_percent},{p_inc},{calc_fitness(train_x[rows],final_test_x,train_y[rows],final_test_y)}\"\n",
    "  all_results.append(new_result)\n",
    "  # print(*result_entry,sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer_classification.csv,10,50,0.5,0.01,0.9935042735042735',\n",
       " 'cancer_classification.csv,20,50,0.5,0.01,0.9911111111111112',\n",
       " 'cancer_classification.csv,30,50,0.5,0.01,0.9907692307692308',\n",
       " 'cancer_classification.csv,40,50,0.5,0.01,0.9876923076923076',\n",
       " 'cancer_classification.csv,50,50,0.5,0.01,0.983931623931624']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in all_results:\n",
    "#   print(*i,sep=\",\")\n",
    "all_results\n",
    "\n",
    "with open(\"new_output.csv\",\"a\") as f:\n",
    "  f.writelines(i+\"\\n\" for i in all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_x,test_x,train_y,test_y=train_test_split(first_train_x_array,first_train_y_array,test_size=0.2,random_state=round(time.time()))\n",
    "# select_percent=0.45\n",
    "# p_inc=0.1 #100\n",
    "# model=PSO(10,15,None,train_x,test_x,train_y,test_y)\n",
    "# rows=model.optimize(select_percent,p_inc)\n",
    "\n",
    "# 0..1+100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result_header=['dataset_name','total_strong_class','strong_class_in_training','strong_class_in_testing','total_rows','selected_rows','select_percent','p_inc','score ']\n",
    "print(*result_header,sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result_entry=[file_name,len(df[df.iloc[:,-1]==1]),np.count_nonzero(train_y[rows]),np.count_nonzero(final_test_y),len(train_x),len(rows),select_percent,p_inc,calc_fitness(train_x[rows],final_test_x,train_y[rows],final_test_y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print(*result_entry,sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_df=pd.read_csv('continuous_results.csv')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grp=new_df.groupby(\"dataset_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,j in grp:\n",
    "  print(i,np.max(j.iloc[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comp_table_df=pd.read_csv(\"comp_table.csv\")\n",
    "comp_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e95b2ef9755d6679a8ad666f5bec9258488f24667f34995d9697b030437f6467"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
